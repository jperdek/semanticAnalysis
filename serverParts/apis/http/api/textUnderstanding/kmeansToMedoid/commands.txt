
# Cleaning data - removing unnecessary parts
python clean_data.py


# Whole process - hadoop
start-all.sh
python3 kmeans_hadoop.py


# Whole process - locally
python mapper.py < data0.txt | sort | reducer.py | cluster_updater.py
python mapper.py < data0.txt | sort | reducer.py | cluster_updater.py > clusters1.txt

python mapper.py clusters0.txt < data0.txt | sort | reducer.py | cluster_updater.py

# Only mapper
python mapper.py < data0.txt | sort

# From mapper to reducer
python mapper.py < data0.txt | sort | reducer.py


# OPTIMIZATION
- set name for your clusters.txt file and optimize it using dictionary_manager.py script!:

usage:
cd serverParts\apis\http\api\textUnderstanding\kmeansToMedoid\optimization
python dictionary_manager.py
fc de-optimized_clusters.txt ../clusters0.txt

result:
Comparing files de-optimized_clusters.txt and ../CLUSTERS0.TXT
FC: no differences encountered